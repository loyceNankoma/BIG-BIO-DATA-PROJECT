{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Machine Learning Project:-\n",
    "\n",
    "Credit to: `Gloria Loyce Nankoma & Ainemambazi Moses`\n",
    "\n",
    "Instructor: `Mugume Twinamatsiko Atwine`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<span style=\"color:#C7920C;\">IMPORT LIBRARIES AND DATASETS.</span>**\n",
    "We begin by importing necessary Libraries and Data sets. these will help us to run our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ydata_profiling as pf\n",
    "from numpy import set_printoptions\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import webbrowser \n",
    "import os \n",
    "# Algorithms\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import clone\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix, auc\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from pandas.core.arrays.sparse import SparseArray as _SparseArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<span style=\"color:#C7920C;\">DATA SET DESCRIPTION</span>**\n",
    "\n",
    "looking at the data set using the data.head() function. Generally it shows different patients with their diferent signs and symptoms as related to mainly 4 dieases. We have learnt the following as explained below\n",
    "\n",
    "- We can identify different signs and symptoms related to different diseases\n",
    "- Under the Disease column We have the healthy,covid-19,HIV, Diabetes and Malaria\n",
    "- Different diseases are related to Sexual orientation,Age, Gender or Race\n",
    "- We learnt the BMI is calculated from Weight and Height.and we know that the higher the BMI the higher the risk of getting diseases like Diabetes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "patients = read_csv('dataset.csv')\n",
    "# Print the first 5 rows of the dataframe.\n",
    "patients.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we used the data.describe() function to calculate various statistical measures for each numerical column in the dataset. it also returns a new DataFrame that includes the following statistical information for each column by default:\n",
    "- count: The number of non-null values in the column.\n",
    "- mean: The arithmetic mean (average) of the values in the column.\n",
    "- std: The standard deviation of the values in the column.\n",
    "- min: The minimum value in the column.\n",
    "- 25%: The first quartile (25th percentile) of the values in the column.\n",
    "- 50%: The second quartile (median or 50th percentile) of the values in the column.\n",
    "- 75%: The third quartile (75th percentile) of the values in the column.\n",
    "- max: The maximum value in the column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse statically insight of data\n",
    "patients.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data info() function shows us that our data set has 10000 rows and 61 columns\n",
    "It shows the column names, the null counts and the data types. we can learn that int64 objects and float64 data types(dtypes: float64(1), int64(56), object(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary of the dataframe\n",
    "#prints information about a DataFrame including the index dtype and columns, non-null values and memory usage\n",
    "patients.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<span style=\"color:#C7920C;\">Exploratary Data Analysis using Pandas Profiling.</span>**\n",
    "This will generate a report that gives basic information about the data types, columns, null value counts, memory usage, etc. EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task. \n",
    "- This helps us to clean our data by identifying missing values, handling outliers and tranforming data types.\n",
    "- It gives a summary statistics such as mean, median, mode, and standard deviation to help understand the distribution of the data.\n",
    "- Through graphs, charts, etc, we are able to visualize the data and identify different patterns, trends, and outliers.\n",
    "- EDA helps us to identify the strength of relationships between variables using correlation and regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<span style=\"color:#C7920C;\">Checking for missing and Null values in our dataset.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_values = patients.columns[patients.isnull().any()]\n",
    "print(f\"Missing values:\\n{patients[miss_values].isnull().sum()}\")\n",
    "\n",
    "null_values = patients.columns[patients.isna().any()]\n",
    "print(f\"Null values:\\n{patients[null_values].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing (patients):\n",
    "    missing_number = patients.isnull().sum().sort_values(ascending=False)\n",
    "    missing_percent = (patients.isnull().sum()/patients.isnull().count()).sort_values(ascending=False)\n",
    "    missing_values = pd.concat([missing_number, missing_percent], axis=1, keys=['Missing_Number', 'Missing_Percent'])\n",
    "    return missing_values\n",
    "\n",
    "missing(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicates\n",
    "patients.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Lets use the histograms to chech how the data in our data frame is balancing. and from the plots we can see that that our data is doing well it even deserves a soda. Except the BMI column that is not balancing well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of the fetal health data\n",
    "patients.hist(figsize=(20,20));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that our data is balanced according to the graph above given by the outcome Variable (Disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = pf.ProfileReport(patients)\n",
    "profile.to_file('patients_Report.html') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:#C7920C;\">PANDAS PROFILLING REPORT.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:#C7920C;\">PREPARE THE DATA</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We checked the value counts for our target column\"Label\". We will check how many classes does our target variable have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.groupby('Label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x ='Label',  data = patients)\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check data types\n",
    "patients.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<span style=\"color:#C7920C;\">DATA TRANSFORMATION</span>**\n",
    "So, there are object data types in our data that We have to convert these labels to numeric (int64) form, so they become machine-readable and we can do this through label encoding:\n",
    "First we call out those that not int64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patients.select_dtypes(include='object')\n",
    "#This cant now work because we have encoded it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def label_encoder(column):\n",
    "    le = LabelEncoder()\n",
    "    patients[column] = le.fit_transform(patients[column])\n",
    "\n",
    "label_list = [\"Gender\", \"Sexual_Orientation\", \"Race\", \"Disease\"]\n",
    "for label in label_list:\n",
    "    label_encoder(label)\n",
    "\n",
    "# Display transformed data\n",
    "patients.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:#C7920C;\">SPLIT THE DATA.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the dataset into independent and dependent variables\n",
    "X = patients.drop([\"Label\"],axis=1)\n",
    "y = patients['Label']\n",
    "#Split the data into training and testing set\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state = 42) \n",
    "#Data was splitted as 80% train data and 20% test data.\n",
    "y_train = y_train.values.reshape(-1,1)\n",
    "y_test = y_test.values.reshape(-1,1)\n",
    "print(\"X_train shape:\",X_train.shape)\n",
    "print(\"X_test shape:\",X_test.shape)\n",
    "print(\"y_train shape:\",y_train.shape)\n",
    "print(\"y_test shape:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:#C7920C;\">STANDARDIZE THE DATA.</span>**\n",
    "We will perform feature scaling to rescale data to have a mean of 0 and standard deviation of 1 (unit variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:#C7920C;\">IMPLEMENT CLASSIFICATION MODELS.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To store results of models, we create two dictionaries\n",
    "result_dict_train = {}\n",
    "result_dict_test = {}\n",
    "\n",
    "#LogisticRegression\n",
    "reg = LogisticRegression(random_state = 42)\n",
    "accuracies = cross_val_score(reg, X_train, y_train, cv=5)\n",
    "reg.fit(X_train,y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "#Obtain accuracy\n",
    "print(\"LogisticRegression Train Score:\",np.mean(accuracies))\n",
    "print(\"LogisticRegression Test Score:\",reg.score(X_test,y_test))\n",
    "#Store results in the dictionaries\n",
    "result_dict_train[\"Logistic Train Score\"] = np.mean(accuracies)\n",
    "result_dict_test[\"Logistic Test Score\"] = reg.score(X_test,y_test)\n",
    "\n",
    "print(\"\\n\" * 2)\n",
    "\n",
    "#KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "accuracies = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "#Obtain accuracy\n",
    "print(\"KNeighborsClassifier Train Score:\",np.mean(accuracies))\n",
    "print(\"KNeighborsClassifier Test Score:\",knn.score(X_test,y_test))\n",
    "#Store results in the dictionaries\n",
    "result_dict_train[\"KNN Train Score\"] = np.mean(accuracies)\n",
    "result_dict_test[\"KNN Test Score\"] = knn.score(X_test,y_test)\n",
    "\n",
    "print(\"\\n\" * 2)\n",
    "#SVM\n",
    "svc = SVC(random_state = 42)\n",
    "accuracies = cross_val_score(svc, X_train, y_train, cv=5)\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "#Obtain accuracy\n",
    "print(\"SVM Train Score:\",np.mean(accuracies))\n",
    "print(\"SVM Test Score:\",svc.score(X_test,y_test))\n",
    "#Store results in the dictionaries\n",
    "result_dict_train[\"SVM Train Score\"] = np.mean(accuracies)\n",
    "result_dict_test[\"SVM Test Score\"] = svc.score(X_test,y_test)\n",
    "\n",
    "print(\"\\n\" * 2)\n",
    "\n",
    "#DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(random_state = 42)\n",
    "accuracies = cross_val_score(dtc, X_train, y_train, cv=5)\n",
    "dtc.fit(X_train,y_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "#Obtain accuracy\n",
    "print(\"DecisionTreeClassifier Train Score:\",np.mean(accuracies))\n",
    "print(\"DecisionTreeClassifier Test Score:\",dtc.score(X_test,y_test))\n",
    "#Store results in the dictionaries\n",
    "result_dict_train[\"Decision Tree Train Score\"] = np.mean(accuracies)\n",
    "result_dict_test[\"Decision Tree Test Score\"] = dtc.score(X_test,y_test)\n",
    "\n",
    "print(\"\\n\" * 2)\n",
    "\n",
    "#RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state = 42)\n",
    "accuracies = cross_val_score(rfc, X_train, y_train, cv=5)\n",
    "rfc.fit(X_train,y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "#Obtain accuracy\n",
    "print(\"RandomForestClassifier Train Score:\",np.mean(accuracies))\n",
    "print(\"RandomForestClassifier Test Score:\",rfc.score(X_test,y_test))\n",
    "#Store results in the dictionaries\n",
    "result_dict_train[\"Random Forest Train Score\"] = np.mean(accuracies)\n",
    "result_dict_test[\"Random Forest Test Score\"] = rfc.score(X_test,y_test)\n",
    "\n",
    "print(\"\\n\" * 2)\n",
    "\n",
    "#GaussianNB\n",
    "gnb = GaussianNB()\n",
    "accuracies = cross_val_score(gnb, X_train, y_train, cv=5)\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "#Obtain accuracy\n",
    "print(\"GaussianNB Train Score:\",np.mean(accuracies))\n",
    "print(\"GaussianNB Test Score:\",gnb.score(X_test,y_test))\n",
    "#Store results in the dictionaries\n",
    "result_dict_train[\"Gaussian NB Train Score\"] = np.mean(accuracies)\n",
    "result_dict_test[\"Gaussian NB Test Score\"] = gnb.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **<span style=\"color:#C7920C;\">COMPARE ACCURACY SCORE.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_result_train = pd.DataFrame.from_dict(result_dict_train,orient = \"index\", columns=[\"Score\"])\n",
    "patients_result_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_result_test = pd.DataFrame.from_dict(result_dict_test,orient = \"index\",columns=[\"Score\"])\n",
    "patients_result_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:#C7920C;\">DISPLAY THE ACCURACY SCORE.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig,ax = plt.subplots(1,2,figsize=(20,5))\n",
    "sns.barplot(x = patients_result_train.index,y = patients_result_train.Score,ax = ax[0])\n",
    "sns.barplot(x = patients_result_test.index,y = patients_result_test.Score,ax = ax[1])\n",
    "ax[0].set_xticklabels(patients_result_train.index,rotation = 75)\n",
    "ax[1].set_xticklabels(patients_result_test.index,rotation = 75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graphs, we can conclude the following:\n",
    "- The LogisticRegression and GaussianNB have the highest test score\n",
    "- The Random Forest classifier has the lowest score among all classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:#C7920C;\">EDITING THE DATA SET</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets drop the highly corelated columns \n",
    "\n",
    "dataDrop= patients.drop(['Weight', 'Height'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDrop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataDrop.drop('Label', axis=1)  # Features\n",
    "y = dataDrop['Label']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())])\n",
    "numeric_features=['Age','Gender','Sexual_Orientation','Race','Weight','Height','BMI',\n",
    "                  'Fever','SwollenLymphNodes','MemoryLoss','Dehydration','IncreasedUrination',\n",
    "                  'DryMouth','TinglingInHandsOrFeet','RedEye','LossOfConsciousness','Disease','Label']\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),  # numeric_features refers to a list of column names with numeric variables\n",
    "          # categorical_features refers to a list of column names with categorical variables\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = preprocessor.fit_transform(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_transformed, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a list of models to train\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeRegressor(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestRegressor(),\n",
    "    RandomForestClassifier(),\n",
    "    SVR(),\n",
    "    SVC()\n",
    "]\n",
    "\n",
    "# Train and evaluate each model on the testing set\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    if isinstance(model, LinearRegression) or isinstance(model, DecisionTreeRegressor) or isinstance(model, RandomForestRegressor) or isinstance(model, SVR):\n",
    "        # For regression models, convert predictions to classes (classification) by rounding to the nearest integer\n",
    "        y_pred_classes = np.round(y_pred)\n",
    "        accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    else:\n",
    "        # For classification models, directly calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "    print(f\"{type(model).__name__}: Testing Accuracy = {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:#C7920C;\">Lets consider the F1 Score</span>**\n",
    "The F1 scores indicate the performance of the models on a specific test set, while the cross-validation scores provide an estimate of their generalization performance across different subsets of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A quick model selection process\n",
    "#pipelines of models( it is short was to fit and pred)\n",
    "pipeline_lr=Pipeline([('lr_classifier',LogisticRegression(random_state=42))])\n",
    "\n",
    "pipeline_dt=Pipeline([ ('dt_classifier',DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "pipeline_rf=Pipeline([('rf_classifier',RandomForestClassifier())])\n",
    "\n",
    "pipeline_svc=Pipeline([('sv_classifier',SVC())])\n",
    "\n",
    "# List of all the pipelines\n",
    "pipelines = [pipeline_lr, pipeline_dt, pipeline_rf, pipeline_svc]\n",
    "\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "pipe_dict = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'RandomForest', 3: \"SVC\"}\n",
    "\n",
    "\n",
    "# Fit the pipelines\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "#cross validation on accuracy \n",
    "cv_results_accuracy = []\n",
    "for i, model in enumerate(pipelines):\n",
    "    cv_score = cross_val_score(model, X_train,y_train, cv=10 )\n",
    "    cv_results_accuracy.append(cv_score)\n",
    "    print(\"%s: %f \" % (pipe_dict[i], cv_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:#C7920C;\">The above scores show that Radom forest and Logistic regression has the highest score. however they also suggest that the models are not learning the patterns or relationships within the data effectively, and their predictions are not much better than random chance thus there is something wrong with the data.</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning Logistic Regression\n",
    "Considering F1 Score of Logistic Regression, we try to tune it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Create an instance of LogisticRegression\n",
    "estimator = LogisticRegression()\n",
    "\n",
    "# Clone the estimator\n",
    "cloned_estimator = clone(estimator)\n",
    "\n",
    "parameters = { \n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [100, 110, 120, 130, 140],\n",
    "    'dual': [True, False]\n",
    "}\n",
    "\n",
    "# Fitting the training set to find parameters with the best accuracy\n",
    "CV_rfc = GridSearchCV(cloned_estimator, param_grid=parameters, cv=5)\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "\n",
    "# Getting the outcome of grid search\n",
    "CV_rfc.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_model = LogisticRegression(**CV_rfc.best_params_)\n",
    "LR_model.fit(X_train, y_train)\n",
    "#Testing the Model on test set\n",
    "predictions=LR_model.predict(X_test)\n",
    "acccuracy= accuracy_score(y_test,predictions)\n",
    "acccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "acccuracy = accuracy_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions, average=\"weighted\")\n",
    "precision = precision_score(y_test, predictions, average=\"weighted\")\n",
    "f1_score = f1_score(y_test, predictions, average=\"micro\")\n",
    "\n",
    "print(\"********* LogisticRegression Results *********\")\n",
    "print(\"Accuracy    : \", acccuracy)\n",
    "print(\"Recall      : \", recall)\n",
    "print(\"Precision   : \", precision)\n",
    "print(\"F1 Score    : \", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:#C7920C;\">The model's performance is quite low, with accuracy, recall, and F1 score all around 0.509. A precision of 0.259081 indicates that there is a relatively high number of false positives, meaning that the model incorrectly predicted many instances as positive. I.</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using BEST K VALUES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "datam = read_csv('dataset.csv')\n",
    "le = LabelEncoder()\n",
    "datam['Gender'] = le.fit_transform(datam['Gender'])\n",
    "datam['Sexual_Orientation'] = le.fit_transform(datam['Sexual_Orientation'])\n",
    "datam['Race'] = le.fit_transform(datam['Race'])\n",
    "datam['Disease']= le.fit_transform(datam['Disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into inputs and outputs\n",
    "values = datam.values\n",
    "X = values[:, :-1]\n",
    "y = values[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a column by index\n",
    "column_index = 8  # Replace '2' with the desired index of the column\n",
    "column = datam.iloc[:, column_index]\n",
    "column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Extract the input features (X) and target variable (y) from the dataset\n",
    "X = datam.drop(\"Label\", axis=1)  # Adjust the column indices as per your dataset\n",
    "y = datam[\"Label\"]   # Adjust the column index for the target variable\n",
    "\n",
    "# Create an instance of SelectKBest with the chi2 scoring function\n",
    "selector = SelectKBest(score_func=chi2, k=10)\n",
    "\n",
    "# Apply feature selection to the input features X and target variable y\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_features = X.columns[selected_feature_indices]\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Selected Features:\")\n",
    "for feature in selected_features:\n",
    "    print(feature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the LR model with random hyperparameters\n",
    "lr = LogisticRegression(penalty='l1',dual=False,max_iter=110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have created the Logistic Regression model with some random hyperparameter values. The hyperparameters that you used are:\n",
    "- penalty : Used to specify the norm used in the penalization (regularization).\n",
    "- dual : Dual or primal formulation. The dual formulation is only implemented for l2 penalty with liblinear solver. Prefer dual=False when n_samples > n_features.\n",
    "- max_iter : Maximum number of iterations taken to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l1', solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdata = datam.drop(columns=['PatientID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass data to the LR model\n",
    "lr.fit(X,y)\n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=110, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "#check accuracy\n",
    "lr.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, we applied your LR model to the same data and evaluated its score. But there is always a need to validate the stability of your machine learning model. You just canâ€™t fit the model to your training data and hope it would accurately work for the real data it has never seen before. You need some kind of assurance that your model has got most of the patterns from the data correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the k-fold cross-validator\n",
    "\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used n_splits as 3, which essentially makes it a 3-fold cross-validation then random_state as 7to reproduce the results but  any integer value  could work as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cross_val_score(lr, X, y, cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual=[True,False]\n",
    "max_iter=[100,110,120,130,140]\n",
    "param_grid = dict(dual=dual,max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "lr = LogisticRegression(penalty='l2')\n",
    "grid = GridSearchCV(estimator=lr, param_grid=param_grid, cv = 3, n_jobs=-1)\n",
    "\n",
    "#start_time = time.time()\n",
    "grid_result = grid.fit(X, y)\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "#print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the selected features\n",
    "selected_features = [\n",
    "    'Age',\n",
    "    'Race',\n",
    "    'Weight',\n",
    "    'ExcessiveThirst',\n",
    "    'BlurredVision',\n",
    "    'Chills',\n",
    "    'SensitivityToLight',\n",
    "    'YellowSkin',\n",
    "    'NasalCongestion',\n",
    "    \n",
    "]\n",
    "\n",
    "# Split the data into features (X) and target variable (y) using the selected features\n",
    "X = datam[selected_features]  # Features using the selected columns\n",
    "y = datam['Label']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate and train the models\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression()),\n",
    "    ('Decision Tree', DecisionTreeClassifier()),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('Support Vector Machine', SVC())\n",
    "]\n",
    "\n",
    "for model_name, model in models:\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"{} Accuracy: {:.2f}\".format(model_name, accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results, we would consider Logisitic Regression Model due to its high Accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
